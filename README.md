ğŸ“˜ SignSight â€“ Real-Time Sign Language Recognition System

A Streamlit-based real-time ASL (American Sign Language) hand gesture recognition app

ğŸŒŸ Overview

SignSight is a real-time Sign Language Detection system built using YOLOv8, OpenCV, and Streamlit.
It recognizes Alphabet letters (Aâ€“Z) and Digits (0â€“9) through live webcam feed and supports Fingerspelling, allowing users to build full words using hand gestures.

This project offers a clean UI, high-speed detection, stable predictions, and a smooth user experience.

âœ¨ Key Features
ğŸ”¤ 1. Alphabet Recognition (Aâ€“Z)

Detects ASL alphabet signs in real time.

Stabilized predictions using majority voting.

Ideal for fingerspelling words.

ğŸ”¢ 2. Digit Recognition (0â€“9)

Detects ASL digits.

Optimized models for fast inference.

âœ‹ 3. Fingerspelling System

Builds words letter-by-letter from hand gestures.

Includes manual controls:

ğŸ”„ Reset

âŒ« Delete

â£ Space

ğŸ—‘ï¸ Clear

ğŸ¥ 4. Smooth Webcam Integration

Low-latency camera feed.

Auto stabilization.

Optimized for Windows (DirectShow - CAP_DSHOW).

ğŸ¨ 5. Professional UI (Streamlit)

Sidebar that includes model selection and controls.

Stats cards for:

Current Prediction

Fingerspelled Word

FPS (Frames per Second)

âš¡ 6. YOLOv8 for Real-Time Detection

Fast and accurate detection.

Custom-trained models for high accuracy.

ğŸ“‚ Project Structure
SignSight/
â”œâ”€â”€ app.py                 # Main Streamlit app
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ letters.pt         # YOLO model for alphabets
â”‚   â””â”€â”€ digits.pt          # YOLO model for digits
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ README.md              # Project documentation

ğŸ› ï¸ Tech Stack
Component	Technology
UI	Streamlit
Detection Model	YOLOv8 (Ultralytics)
Backend	Python
Image Processing	OpenCV
Stabilization	Majority Vote Buffer
Deployment	Local / GitHub
ğŸš€ How to Run Locally
1ï¸âƒ£ Install dependencies
pip install -r requirements.txt

2ï¸âƒ£ Run the app
streamlit run app.py

3ï¸âƒ£ Allow camera access when prompted.
ğŸ“Œ How It Works

User selects Alphabet Model or Digit Model.

The webcam stream starts.

YOLOv8 detects hand gestures in real-time.

For alphabets:

Predictions are stabilized using a sliding window.

The system adds letters into a word (fingerspelling).

UI displays:

Live camera feed

Current prediction

Fingerspelling word

FPS

ğŸ“Š Fingerspelling Logic

To prevent jitter and wrong characters:

A prediction buffer stores last N predictions.

The system chooses the most frequent (stable) prediction.

Only adds a new character when:

It appears enough times

It is different from the last added one

This ensures:

No duplicate letters

Stable and accurate fingerspelling

Smooth typing-like experience

ğŸ§ª Training Details

Trained on ASL datasets for:

Alphabets Aâ€“Z

Digits 0â€“9

YOLOv8n model (optimized for speed)

Augmentations:

Rotation

Brightness

Flip

Hand position variation

ğŸ“ Requirements

Your requirements.txt should include:

ultralytics
opencv-python
numpy
streamlit


ğŸ¯ Future Improvements

Word-level recognition

Sentence-level translation

Audio output

Support for Indian Sign Language (ISL)

Better mobile-friendly UI

ğŸ‘©â€ğŸ’» Contributors

Muskan Dawar â€“ Developer

Model Training Support

UI/UX Implementation

Streamlit Integration

ğŸ‰ Thank you for exploring SignSight!

If you like the project, â­ the repo on GitHub!