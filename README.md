**S I G N S I G H T**


Seamless Interpretation & Gesture Navigation System

SignSight is a real-time Sign Language Recognition system designed to translate hand gestures into English alphabets, digits, and basic words. Built using YOLO, OpenCV, and Streamlit, the project aims to support inclusive communication with a fast, intuitive, and modern UI.

The system is optimized for students, developers, and assistive technology experiments, delivering smooth inference and stable gesture detection.

â¸» **Overview**

SignSight captures live webcam input, detects hand signs using a custom-trained YOLO model, and outputs predictions with smoothing for higher stability.
Features include fingerspelling mode, word detection, and a minimal, accessible interface.

With Streamlitâ€™s responsive UI design and lightweight model loading, SignSight is ideal for demos, academic projects, and rapid experimentation.

â¸» **Key Features**

**ğŸ¯ Real-Time Gesture Detection**

â— YOLO-based sign recognition

â— Supports Aâ€“Z alphabets, 0â€“9 digits, and basic words

â— High-confidence filtering for accuracy



**ğŸ”¤ Fingerspelling Mode**

â— Predicts letters sequentially

â— Builds words character-by-character

â— Ideal for ASL practice and learning



**ğŸ§  Stable Prediction Engine**

â— Uses a rolling history (deque)

â— Outputs the most consistent result for stable detection



**ğŸ¨ Modern Streamlit UI**

â— Clean, intuitive layout

â—Live camera feed preview

â— Responsive and minimal design



**âš¡ Efficient & Lightweight**

â— Runs smoothly on CPU

â— Supports manual or automatic model loading




â¸» **Methodology**

1. Frame Capture

Input frames are processed via OpenCV with optimized resizing.

2. YOLO-Based Detection

Each frame is passed through the trained YOLO model for class predictions.

3. Confidence Thresholding

Low-confidence predictions are filtered out.

4. History-Based Smoothing

A rolling buffer stores past predictions to improve stability.

5. Streamlit Rendering

The UI displays the live feed and predictions in real time.

This workflow ensures balance between speed, accuracy, and stability.

â¸» **Model Downloads**

Your YOLO models are stored in Google Drive due to size limits.

ğŸ“¦ Letters Model (256 MB)

Direct Download:
ğŸ‘‰ https://drive.google.com/uc?export=download&id=1IvBFgoHSmMqUC8qWTFfah7T0HMyvhQck

ğŸ”¢ Digits Model (85 MB)

Direct Download:
ğŸ‘‰ https://drive.google.com/uc?export=download&id=1XhB9wbBni09N90GHhAUFUBWJfFh2H2zO

âš ï¸ Place downloaded models in:
```
project/
 â””â”€â”€ model/
      â”œâ”€â”€ letters.pt
      â””â”€â”€ digits.pt
```

â¸» Installation
1.  Clone the Repository
```
git clone https://github.com/muskan-1301/Fake_signsight.git
cd Fake_signsight
```

2.  Install Dependencies
```
pip install -r requirements.txt
```

3.  Run the Application
```
streamlit run app.py
```

â¸» Project Structure
```
SignSight/
â”‚
â”œâ”€â”€test.py                 # run locally
â”œâ”€â”€ app.py                 # Main application file
â”œâ”€â”€ model/                 # YOLO model files (download & place here)
â”‚     â”œâ”€â”€ letters.pt
â”‚     â””â”€â”€ digits.pt
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md              # Documentation
```

â¸» **Future Improvements**

â— Two-hand gesture support

â— Larger ASL word vocabulary

â— Auto-spacing for fingerspelling

â— Noise-resistant low-light tracking

â— TensorFlow Lite mobile version

â— Speech output integration




**NOTE:**

This project was created for academic/educational purposes only.
